{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wget using reject, THEN accept!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries for smart use of wget\n",
    "import os, csv\n",
    "import shutil\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlparse\n",
    "from socket import error as SocketError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting directories\n",
    "micro_sample13 = \"/vol_b/data/Charter-school-identities/data/micro-sample13_coded.csv\"\n",
    "full_data = \"/vol_b/data/Charter-school-identities/data/charter_URLs_2014.csv\"\n",
    "wget_folder = \"/vol_b/data/wget/Nov_2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.richland2.org'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlparse('https://www.richland2.org/CharterHigh/About-Us').hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_link(text):\n",
    "    \"\"\"Function to get parents' links. Return a list of valid links.\"\"\"\n",
    "    ls= get_parent_link_helper(5, text, []);\n",
    "    if len(ls) > 1:\n",
    "        return ls[0]\n",
    "    return str\n",
    "\n",
    "def get_parent_link_helper(level, text, result):\n",
    "    \"\"\"This is a tail recursive function\n",
    "    to get parent link of a given link. Return a list of urls \"\"\"\n",
    "    if level == 0 or not check(str):\n",
    "        return ''\n",
    "    else:\n",
    "        result += [text]\n",
    "        return get_parent_link_helper(num -1, str[: text.rindex('/')], result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_folder_name (k, name):\n",
    "    \"\"\"Format a folder nicely for easy access\"\"\"\n",
    "    if k < 10: # Add two zeros to the folder name if k is less than 10 (for ease of organizing the output folders)\n",
    "        dirname = \"00\" + str(k) + \" \" + name\n",
    "    elif k < 100: # Add one zero if k is less than 100\n",
    "        dirname = \"0\" + str(k) + \" \" + name\n",
    "    else: # Add nothing if k>100\n",
    "        dirname = str(k) + \" \" + name\n",
    "    return dirname\n",
    "\n",
    "def contains_html(my_folder):\n",
    "    \"\"\"check if a wget is success by checking if a directory has a html file\"\"\"\n",
    "\n",
    "    for r,d,f in os.walk(my_folder):\n",
    "        for file in f:\n",
    "            if file.endswith('.html'):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def count_with_file_ext(folder, ext):\n",
    "    count = 0\n",
    "    for r,d,f in os.walk(my_folder):\n",
    "        for file in f:\n",
    "            if file.endswith(ext):\n",
    "                count +=1\n",
    "    return count \n",
    "\n",
    "# write a file and add num line at the beginning of line\n",
    "def write_to_file(num, link, file_name):\n",
    "    with open(file_name, \"a\") as text_file:\n",
    "        text_file.write(str(num) + \"\\t\" + link +\"\\n\")\n",
    "\n",
    "# just write str to file\n",
    "def write_file(str, file_name):\n",
    "    with open(file_name, \"a\") as text_file:\n",
    "        text_file.write(str)\n",
    "        \n",
    "def reset(folder, text_file_1, text_file_2):\n",
    "    \"\"\"Deletes all files in a folder and set 2 text files to blank\"\"\"\n",
    "    parent_folder = folder[: folder.rindex('/')]\n",
    "    shutil.rmtree(folder)\n",
    "    os.makedirs(folder)\n",
    "    filelist = [ f for f in os.listdir(folder) if f.endswith(\".bak\") ]\n",
    "    for f in filelist:\n",
    "        os.unlink(f)\n",
    "    for file_name in [text_file_1, text_file_2]:\n",
    "        reset_text_file(file_name)\n",
    "        \n",
    "def reset_text_file(file_name):\n",
    "    if os.path.exists(file_name):\n",
    "            with open(file_name, \"w\") as text_file:\n",
    "                text_file.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "030 name me\n"
     ]
    }
   ],
   "source": [
    "#testing methods\n",
    "print(format_folder_name(30, \"name me\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(url):\n",
    "    \"\"\" Helper function, check if url is a valid list\"\"\"\n",
    "    try:\n",
    "        urlopen(url)\n",
    "        \n",
    "    except urllib.error.URLError:\n",
    "        print(\"urllib.error.URLError\")\n",
    "        return False\n",
    "    except urllib.error.HTTPError:\n",
    "        print('urllib.error.HTTPError')\n",
    "        return False\n",
    "    except SocketError:\n",
    "        print('SocketError')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def read_txt(txt_file):\n",
    "    links = []\n",
    "    count = 0\n",
    "    with open(txt_file) as f:\n",
    "        for line in f:   \n",
    "            \n",
    "            elem =  line.split('\\t')[1].rstrip()\n",
    "            count +=1\n",
    "    \n",
    "#             print(elem)\n",
    "            links += [elem.rstrip()]\n",
    "    return links, count\n",
    "\n",
    "def read_txt_2(txt_file):\n",
    "    links = []\n",
    "    count = 0\n",
    "    with open(txt_file) as f:\n",
    "        for line in f:   \n",
    "            \n",
    "#             elem =  line.split('\\t')[1].rstrip()\n",
    "#             if elem.endswith('\\'):\n",
    "#                 elem = elem[:-1]\n",
    "            count +=1\n",
    "    \n",
    "#             print(elem)\n",
    "            links += [line.rstrip()]\n",
    "    return links, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_valid_links(list_of_links, valid_file, invalid_file):\n",
    "    count_success, count_fail = 0, 0\n",
    "    valid, invalid = '', ''\n",
    "    for l in list_of_links:\n",
    "#         print(l)\n",
    "        if check(l):\n",
    "            valid += l + '\\n'\n",
    "            count_success +=1\n",
    "        else:\n",
    "            invalid += l + '\\n'\n",
    "            count_fail += 1\n",
    "#             print(l)\n",
    "    write_file(valid, valid_file)\n",
    "    write_file(invalid, invalid_file)\n",
    "    return count_success, count_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wget_command(link, parent_folder, my_folder):\n",
    "    \"\"\"wget on link and print output to appropriate folders. Uses two kinds of wget:\n",
    "    Reject approach is more comprehensive and thus restrictive, we'll try it first;\n",
    "    If that doesn't give any .html files, then use accept approach! This gives less results but is more reliable.\n",
    "    \"\"\"\n",
    "    \n",
    "    os.chdir(parent_folder) #navigate to parent folder\n",
    "    if not os.path.exists(my_folder): #create dir my_folder if it doesn't exist yet\n",
    "        os.makedirs(my_folder)\n",
    "    os.chdir(my_folder) #navigate to the correct folder, ready to wget\n",
    "    specific_folder = parent_folder + '/'+ my_folder\n",
    "    \n",
    "    # Define parameters for wget command\n",
    "    wget_reject_options = '\\\n",
    "    --no-parent --show-progress --progress=dot --page-requisites --recursive --append-output=wgetNov17_log --level inf \\\n",
    "    --warc-file={} --warc-cdx --directory-prefix= ' + parent_folder + ' --referer= ' + get_parent_link(link) + ' \\\n",
    "    --random-wait --timestamping --show-progress --progress=dot --verbose \\\n",
    "    --no-remove-listing --follow-ftp --no-clobber --adjust-extension --convert-links \\\n",
    "    --retry-connrefused --tries=10 -execute robots=off --no-cookies --header \"Host: jrs-s.net\" --secure-protocol=auto --no-check-certificate \\\n",
    "    --user-agent=\"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:11.0) Gecko/20100101 Firefox/11.0\" \\\n",
    "    --reject .mov,.MOV,.avi,.AVI,.mpg,.MPG,.mpeg,.MPEG,.mp3,.MP3,.mp4,.MP4,.ppt,.PPT,.pptx,.PPTX'\n",
    "    \n",
    "    wget_accept_options = '\\\n",
    "    --no-parent --show-progress --progress=dot --page-requisites --recursive --append-output=wgetNov17_log --level inf \\\n",
    "    --warc-file={} --warc-cdx --directory-prefix= ' + parent_folder + ' --referer= ' + get_parent_link(link) + ' \\\n",
    "    --random-wait --timestamping --show-progress --progress=dot --verbose \\\n",
    "    --no-remove-listing --follow-ftp --no-clobber --adjust-extension --convert-links \\\n",
    "    --retry-connrefused --tries=10 -execute robots=off --no-cookies --header \"Host: jrs-s.net\" --secure-protocol=auto --no-check-certificate \\\n",
    "    --user-agent=\"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:11.0) Gecko/20100101 Firefox/11.0\" \\\n",
    "    --accept .htm,.html,.asp,.aspx,.php,.shtml,.cgi,.php,.pl,.jsp'\n",
    "    \n",
    "    # Run wget reject, then wget accept if necessary!\n",
    "    os.system('parallel -j 100 wget ' + wget_reject_options + ' ' + link) #use concurrency to speed up the web-crawl\n",
    "    if not contains_html(specific_folder):\n",
    "        os.system('parallel -j 100 wget ' + wget_accept_options + ' ' + link) #back-up plan if reject fails: wget accept!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/vol_b/data/Charter-school-identities/data/micro-sample13_coded.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-da224ad43214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# make empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmicro_sample13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# open file; the windows-1252 encoding looks weird but works for this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create a reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# loop through rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# append each row to the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/vol_b/data/Charter-school-identities/data/micro-sample13_coded.csv'"
     ]
    }
   ],
   "source": [
    "sample = [] # make empty list\n",
    "with open(micro_sample13, 'r', encoding = 'Latin1')\\\n",
    "as csvfile: # open file\n",
    "    reader = csv.DictReader(csvfile) # create a reader\n",
    "    for row in reader: # loop through rows\n",
    "        sample.append(row) # append each row to the list\n",
    "        \n",
    "#note: each row, sample[i] is a dictionary with keys as column name and value as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning this into tuples we can use with wget!\n",
    "# first, make some empty lists\n",
    "url_list = []\n",
    "name_list = []\n",
    "terms_list = []\n",
    "\n",
    "# now let's fill these lists with content from the sample\n",
    "for school in sample:\n",
    "    url_list.append(school[\"URL\"])\n",
    "    name_list.append(school[\"SCHNAM\"])\n",
    "    terms_list.append(school[\"ADDRESS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://www.richland2.org/charterhigh/', 'RICHLAND TWO CHARTER HIGH'), ('https://www.polk.edu/lakeland-gateway-to-college-high-school/', 'POLK STATE COLLEGE COLLEGIATE HIGH SCHOOL'), ('https://www.nhaschools.com/schools/rivercity/Pages/default.aspx', 'RIVER CITY SCHOLARS CHARTER ACADEMY')]\n",
      "\n",
      " Polk State College Collegiate High School\n"
     ]
    }
   ],
   "source": [
    "tuple_list = list(zip(url_list, name_list))\n",
    "# Let's check what these tuples look like:\n",
    "print(tuple_list[:3])\n",
    "print(\"\\n\", tuple_list[1][1].title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0 # initialize this numerical variable k, which keeps track of which entry in the sample we are on.\n",
    "\n",
    "#testing the first 10 tuples\n",
    "tuple_test = tuple_list[:10]\n",
    "\n",
    "\n",
    "for tup in tuple_test:\n",
    "    school_title = tup[1].title()\n",
    "\n",
    "    k += 1 # Add one to k, so we start with 1 and increase by 1 all the way up to entry # 300\n",
    "    print(\"Capturing website data for\", school_title + \", which is school #\" + str(k), \"of 300...\")\n",
    "    \n",
    "    # use the tuple to create a name for the folder\n",
    "    dirname = format_folder_name(k, school_title)\n",
    "    \n",
    "    run_wget_command(tup[0], wget_folder, dirname)\n",
    "    \n",
    "    school_folder = wget_folder + '/'+ dirname\n",
    "\n",
    "print(\"done!\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitation of wget\n",
    "\n",
    "-only works for static HTML and it doesnâ€™t support JavaScript. Thus any element generated by JS will not be captured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More info:\n",
    "\n",
    "https://www.petekeen.net/archiving-websites-with-wget\n",
    "\n",
    "http://askubuntu.com/questions/411540/how-to-get-wget-to-download-exact-same-web-page-html-as-browser\n",
    "\n",
    "https://www.reddit.com/r/linuxquestions/comments/3tb7vu/wget_specify_dns_server/\n",
    "failed: nodename nor servname provided, or not known.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
